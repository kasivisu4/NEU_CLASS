{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasivisu4/NEU_CLASS/blob/main/Algorithms_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDc7TM9BYMQ7",
        "outputId": "67588cb0-0a9c-43d1-f658-e45ac398f0db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvZpY9N4ek1M",
        "outputId": "af82c302-db85-4d39-9a3b-b7c04483423b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anytree\n",
            "  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▉                        | 10 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 20 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 30 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 40 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 550 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from anytree) (1.15.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.8.0\n"
          ]
        }
      ],
      "source": [
        "pip install anytree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5V8Krl3eNRT"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from anytree import Node, RenderTree\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qds_pFhzhiIR"
      },
      "outputs": [],
      "source": [
        "\n",
        "root=Node(\"root\")\n",
        "nodes={}\n",
        "nodes[root.name]=root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRyz8x_D0niT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# we create the key representing the start char of every word in the sentence like if the sentence is like \"can we create the key and find similar keys?\" in the alphabet sequence array\n",
        "# The advantage of this approach is that we can find the similar keys in short time\n",
        "# The first_char_array_title will contains [c,w,t,k,a,f,s] unique values\n",
        "# The key will be 10100100001000000011001000 because we assign \n",
        "# \n",
        "# for Char 'c' => arr[2]=1 ; Char 'w' => arr[22]=1 ; Char 't' => arr[19]=1 ; Char 'k' => arr[10]=1 ; Char 'a' => arr[0]=1 ; Char 'f' => arr[5]=1 ; Char 's' => arr[18]=1 ; \n",
        "\n",
        "def create_node_key(title):\n",
        "\n",
        "    # char_array = ['0']*26\n",
        "    first_char_array_title =set(map(lambda x: x[0].lower() if x[0].lower()<='z' and x[0].lower()>='a' else \"\" ,filter(lambda x:x!=\"\",title.strip().split(' '))))\n",
        "    char_array = first_char_array_title\n",
        "    # for start_char in first_char_array_title:\n",
        "    #     index= ord(start_char.lower()) - ord('a')\n",
        "    #     if  index >=0 and index<=25:\n",
        "    #         char_array[index] = '1'\n",
        "\n",
        "    key = \"\".join(char_array)\n",
        "    return key\n",
        "\n",
        "# # We are finding the similar keys by making the key into binary format and simply using the bitwise and operator to see if the values !=0 which means the key1 and key2 are having similar keys\n",
        "# def cmp_key(key1,key2):\n",
        "#     return (eval('0b' + key1) & eval('0b' + key2) !=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6F-DGhewIM3"
      },
      "outputs": [],
      "source": [
        "\n",
        "tree_pointer = {}\n",
        "tree_pointer [\"Segment Title\"]={}\n",
        "tree_pointer [\"Family Title\"]={}\n",
        "tree_pointer [\"Class Title\"]={}\n",
        "tree_pointer [\"Commodity Title\"]={}\n",
        "\n",
        "\n",
        "def create_Node(data,title):\n",
        "    try:\n",
        "      global tree_pointer\n",
        "      parent_key=\"\"\n",
        "      if (data[\"key\"].strip()==''):\n",
        "          return\n",
        "\n",
        "      node_key = create_node_key(data['title'])\n",
        "      if node_key in tree_pointer[title]:\n",
        "        parent_key = tree_pointer[title][node_key]\n",
        "    \n",
        "      else:\n",
        "         tree_pointer[title][node_key] = Node(node_key,parent=nodes[title])\n",
        "         parent_key =  tree_pointer[title][node_key]\n",
        "\n",
        "      if not data[\"title\"] in set(map(lambda child: child.name,parent_key.children)):   \n",
        "          Node(data[\"title\"],parent=parent_key,data=data)\n",
        "\n",
        "    except:\n",
        "      print(sys.exc_info()[2])\n",
        "      print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGcTSfecY65w"
      },
      "source": [
        "Data Extraction from the UNSPSC File and storing the data in the tree structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO05LAG2X9JP"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/UNSPSC_English.csv',encoding=\"utf8\") as unspsc_file:\n",
        "    [ next(unspsc_file) for _ in range(9)]   \n",
        "    unspsc_reader = csv.DictReader(unspsc_file, delimiter=',')\n",
        "    [ next(unspsc_reader) for _ in range(2)] \n",
        "    titles=[[\"Segment Title\",\"Segment\"],[\"Family Title\",\"Family\"],[\"Class Title\",\"Class\"],[\"Commodity Title\",\"Commodity\"]]\n",
        "    for title in titles:\n",
        "      nodes[title[0]] = Node(title[0],parent=root)\n",
        "\n",
        "    for line in unspsc_reader:\n",
        "      for index in range(0,len(titles)):\n",
        "        create_Node({\"title\" : line[titles[index][0]],\"key\":line[titles[index][1]]},titles[index][0])\n",
        "\n",
        "          \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6NrWjt-Qgfi"
      },
      "source": [
        "**Unique Values of titles in UNSPSC File**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r67wSihmME-P",
        "outputId": "6229c4bd-8eed-4249-96b1-5c61ce82a4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segement Title Leaves Count:  57                  Segement Title Children Count:  57\n",
            "Family Title Leaves Count:  546                   Family Title Children Count:  425\n",
            "Class Title Leaves Count:  7902                   Class Title Children Count:  3328\n",
            "Commodity Title Leaves Count:  147893             Commodity Title Children Count:  30797\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Segement Title Leaves Count: \",len(nodes[\"Segment Title\"].leaves),\"                 Segement Title Children Count: \",len(nodes[\"Segment Title\"].children))\n",
        "\n",
        "print(\"Family Title Leaves Count: \",len(nodes[\"Family Title\"].leaves),\"                  Family Title Children Count: \",len(nodes[\"Family Title\"].children))\n",
        "\n",
        "print(\"Class Title Leaves Count: \",len(nodes[\"Class Title\"].leaves),\"                  Class Title Children Count: \",len(nodes[\"Class Title\"].children))\n",
        "\n",
        "print(\"Commodity Title Leaves Count: \",len(nodes[\"Commodity Title\"].leaves),\"            Commodity Title Children Count: \",len(nodes[\"Commodity Title\"].children))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gu-98LgeLu_"
      },
      "outputs": [],
      "source": [
        "from anytree.exporter import DotExporter\n",
        "DotExporter(nodes[\"Segment Title\"]).to_picture(\"Segment_title.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlA4T8jqaqZ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkslZk1wcLqj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('/content/drive/My Drive/Colab Notebooks/Avalara_goods_and_services.xlsx', 'goods_and_services', header=1)\n",
        "data_array = np.array(df)\n",
        "avalara_file = data_array[1706:2547]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ov1SuF8bExA"
      },
      "outputs": [],
      "source": [
        "create_node_key_vf = np.vectorize(create_node_key)\n",
        "avalara_file = np.column_stack((avalara_file, create_node_key_vf(avalara_file[:,1])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memoization = {}\n",
        "memoization[\"Commodity Title\"] = {}\n",
        "memoization[\"Class Title\"] = {}\n",
        "memoization[\"Family Title\"] = {}\n",
        "memoization[\"Segment Title\"] = {}\n",
        "\n",
        "def store_leave_addr():\n",
        "    for level in tree_pointer:\n",
        "        for node in tree_pointer[level]:\n",
        "            for i in node:\n",
        "                if i in memoization[level]:\n",
        "                    for k in tree_pointer[level][node].children:\n",
        "                      memoization[level][i].append(k)\n",
        "                else:\n",
        "                    memoization[level][i] = []\n",
        "                    for k in tree_pointer[level][node].children:\n",
        "                      memoization[level][i].append(k)"
      ],
      "metadata": {
        "id": "34kEKBVQb7cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_leave_addr()"
      ],
      "metadata": {
        "id": "v0GbB_dJlIkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaecoK7Hjmrb"
      },
      "outputs": [],
      "source": [
        "def search_tree(key,level):\n",
        "    key_match = []\n",
        "    global memoization\n",
        "    # key_match[\"Commodity Title\"] = {}\n",
        "    # key_match[\"Class Title\"] = {}\n",
        "    # key_match[\"Family Title\"] = {}\n",
        "    # key_match[\"Segment Title\"] = {}\n",
        "    for i in key:\n",
        "        if i in memoization[level]:\n",
        "          for j in memoization[level][i]:\n",
        "              key_match.append(j)\n",
        " \n",
        "    return key_match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehcp7J1oSrTD"
      },
      "outputs": [],
      "source": [
        "def longestCommonSubsequence(text1, text2):\n",
        "\n",
        "    text1 = text1.lower().split(\" \")\n",
        "    text2 = text2.lower().split(\" \")\n",
        "    \n",
        "    if len(text1) > len(text2):\n",
        "        text2,text1 = text1,text2  \n",
        "    arr = [[0 for i in range(len(text2)+1)] for j in range(2)]\n",
        "    \n",
        "    b=1\n",
        "    for i in range (1,len(text1)+1):    \n",
        "        b= i & 1\n",
        "        for j in range(1,len(text2)+1):\n",
        "            if text1[i-1] == text2[j-1]:\n",
        "                arr[1-b][j]= arr[b][j-1]+1\n",
        "            else:\n",
        "                arr[1-b][j] = max(arr[b][j],arr[1-b][j-1])\n",
        "    \n",
        "    return arr[1-b][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnuYSmQulCjP"
      },
      "outputs": [],
      "source": [
        "ans = {}\n",
        "count = 0 \n",
        "total_length_avalara_file = len(avalara_file)\n",
        "per_done = 0\n",
        "def cmp_avalara_unspsc():\n",
        "  global ans,count,total_length_avalara_file,per_done\n",
        "  for data in avalara_file:\n",
        "    count+=1\n",
        "    per_done = count * 100 /total_length_avalara_file\n",
        "    levels = [\"Segment Title\",\"Family Title\",\"Class Title\",\"Commodity Title\"]\n",
        "    for level in levels:\n",
        "      for match in (search_tree(data[3],level)):\n",
        "        avalara_desc = data[1]\n",
        "        unspsc_desc = match.data[\"title\"]\n",
        "        avalara_length = len(avalara_desc.split(\" \"))\n",
        "        unspsc_length = len(unspsc_desc.split(\" \"))\n",
        "        min_length = unspsc_length if (avalara_length > unspsc_length) else avalara_length\n",
        "        thresold = 0.6\n",
        "        match_perc = (longestCommonSubsequence(unspsc_desc,avalara_desc))/min_length\n",
        "        if (match_perc >= thresold):\n",
        "            if avalara_desc in ans:\n",
        "              if level in ans[avalara_desc]:\n",
        "                ans[avalara_desc][level].append({\"unspsc_text\" : unspsc_desc,\"match_ratio\" : match_perc })\n",
        "              else:\n",
        "                ans[avalara_desc][level] = []\n",
        "                ans[avalara_desc][level].append({\"unspsc_text\" : unspsc_desc,\"match_ratio\" : match_perc })\n",
        "\n",
        "            else:\n",
        "              ans[avalara_desc] ={}\n",
        "              ans[avalara_desc][level] = []\n",
        "              ans[avalara_desc][level].append({\"unspsc_text\" : unspsc_desc,\"match_ratio\" : match_perc,\"min_length\" : min_length })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U59Zp5ztozx_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "317897fc-0f26-4701-f3b8-40dff24d1909"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-fbc98b854bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcmp_avalara_unspsc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-106-3fe1cb52d3cc>\u001b[0m in \u001b[0;36mcmp_avalara_unspsc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmin_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munspsc_length\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavalara_length\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0munspsc_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mavalara_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mthresold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmatch_perc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlongestCommonSubsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munspsc_desc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavalara_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmatch_perc\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthresold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mavalara_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-f508ba04769b>\u001b[0m in \u001b[0;36mlongestCommonSubsequence\u001b[0;34m(text1, text2)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "cmp_avalara_unspsc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M41NjvBsbI6T",
        "outputId": "2169a18d-1b1b-4a18-93ff-1343fc807c2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "len(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwpPZZbBbQka"
      },
      "outputs": [],
      "source": [
        "# Save the DataFrame to a file on the Colab backend.\n",
        "import json\n",
        "with open('ans.json', 'w') as f:\n",
        "  f.write(json.dumps(ans) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUaUXREPPfV9"
      },
      "outputs": [],
      "source": [
        "from anytree.search import find \n",
        "list(map(lambda child_nodes: find(child_nodes,lambda node: node.name == \"Land and Buildings and Structures and Thoroughfares\"),root.children))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Algorithms_project_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}